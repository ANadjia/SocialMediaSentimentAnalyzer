{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/cleaned_data1.csv')\n",
    "data = pd.read_csv(\"../DATA/cleaned_data1.csv\", names=[\"tweet\", \"class\"]).iloc[2:,:]\n",
    "data[\"class\"] = np.where(data[\"class\"] == \"Positive\",1,0)\n",
    "data = data.sample(frac = 1)\n",
    "x = data['tweet'].apply(lambda x : str(x).split()).to_list()\n",
    "y = data['class'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['len'] = [len(tweet) for tweet in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data['len']) - cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpt = 0\n",
    "#for i in range(len(data)) :\n",
    "    #tweet = data.iloc[i]\n",
    "    #if tweet['len'] < 500 :\n",
    "        #cpt += 1\n",
    "        \n",
    "#print(cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test= train_test_split(x,y,test_size=0.25,random_state=42 , stratify=y)  #same random state \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word Embedding Models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etudiant\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "\n",
    "# FastText :\n",
    "ft_model_sg   = FastText.load(\"../CODE/EmbeddingModels/ft_model_sg.model\")\n",
    "ft_model_cbow  = FastText.load(\"../CODE/EmbeddingModels/ft_model_cbow.model\")\n",
    "\n",
    "# Word2vec :\n",
    "w2v_model_sg   = Word2Vec.load(\"../CODE/EmbeddingModels/w2v_model_sg.model\")\n",
    "w2v_model_cbow = Word2Vec.load(\"../CODE/EmbeddingModels/w2v_model_cbow.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 100000\n",
    "embedding_dim = 300\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions :  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Max lenght of sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the Max length of sentences : \n",
    "def get_max_length(data):\n",
    "    max_length = 0\n",
    "    for index in range(len(data)) : \n",
    "        number_words = len(data[index])\n",
    "        if (number_words) > (max_length):\n",
    "            max_length = number_words\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_data = 500\n"
     ]
    }
   ],
   "source": [
    "max_len_data = get_max_length(x)\n",
    "max_len_data = 500\n",
    "\n",
    "print(f\"max_len_data = {max_len_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# create the tokenizer\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total words : 174770\n"
     ]
    }
   ],
   "source": [
    "total_words = len(tokenizer.word_index) +1\n",
    "print(f\" Total words : {total_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get embedding matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(model,data,embedding_dim, max_nb_words, total_words,tokenizer):\n",
    "     \n",
    "    skipped_words = 0 \n",
    "    embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        # embedding_vector = None\n",
    "        try:\n",
    "            embedding_vector = model.wv[word]\n",
    "        except :\n",
    "            skipped_words += 1\n",
    "            pass\n",
    "        if embedding_vector is not None :\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_matrix_ft_sg    = get_embedding_matrix(ft_model_sg,   x,embedding_dim,MAX_NB_WORDS,total_words,tokenizer)\n",
    "embedding_matrix_ft_cbow  = get_embedding_matrix(ft_model_cbow, x,embedding_dim,MAX_NB_WORDS,total_words,tokenizer)\n",
    "embedding_matrix_w2v_sg   = get_embedding_matrix(w2v_model_sg,  x,embedding_dim,MAX_NB_WORDS,total_words,tokenizer)\n",
    "embedding_matrix_w2v_cbow = get_embedding_matrix(w2v_model_cbow,x,embedding_dim,MAX_NB_WORDS,total_words,tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and testing data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Data  :\n",
    "\n",
    "padding_X_train = pad_sequences(tokenizer.texts_to_sequences(X_train),maxlen = max_len_data)\n",
    "padding_X_test  = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen = max_len_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(embedding_layer):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Conv1D(100,5,activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(2,2))\n",
    "    model.add(Conv1D(50,2,activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(2,2))\n",
    "    model.add(Conv1D(30,2,activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(2,2))\n",
    "    model.add(Conv1D(50,2,activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(2,2))\n",
    "    model.add(Dense(10,activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_test,predictions, file ,info ):\n",
    "    file.write(\"\\n Le model : \" + str(info)+\"\\n\")  \n",
    "    file.write(\"Confusion Matrix : \\n\" + str(confusion_matrix(y_test,predictions))+\"\\n\")  \n",
    "    file.write(\"Classification Report : \\n\" + str(classification_report(y_test,predictions))+\"\\n\")  \n",
    "    file.write(\"Accuracy score : \\n\"+str(accuracy_score(y_test, predictions))+\"\\n\")\n",
    "    file.write(\"Recall Score : \\n\" + str(recall_score(y_test,predictions))+\"\\n\")\n",
    "    file.write(\"F1-score : \\n\" + str(f1_score(y_test, predictions, zero_division=1))+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embedding layers : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data :\n",
    "embedding_layer_ft_sg    = Embedding(total_words, embedding_dim, weights=[embedding_matrix_ft_sg], input_length   =max_len_data)\n",
    "embedding_layer_ft_cbow  = Embedding(total_words, embedding_dim, weights=[embedding_matrix_ft_cbow], input_length =max_len_data)\n",
    "embedding_layer_w2v_sg   = Embedding(total_words, embedding_dim, weights=[embedding_matrix_w2v_sg], input_length  =max_len_data)\n",
    "embedding_layer_w2v_cbow = Embedding(total_words, embedding_dim, weights=[embedding_matrix_w2v_cbow], input_length=max_len_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CNN models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data :\n",
    "model_ft_sg    = model(embedding_layer_ft_sg)\n",
    "model_ft_cbow  = model(embedding_layer_ft_cbow)\n",
    "model_w2v_sg   = model(embedding_layer_w2v_sg)\n",
    "model_w2v_cbow = model(embedding_layer_w2v_cbow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(cnn_model,x_test,y_test):\n",
    "    \n",
    "    predictions    = cnn_model.predict(x_test)\n",
    "    predictions    = [predictions[i][0] for i in range(len(predictions))]\n",
    "    predict_result = [round(num) for num in predictions]\n",
    "\n",
    "    return predict_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = padding_X_train\n",
    "y_train = y_train\n",
    "\n",
    "X_test = padding_X_test\n",
    "y_test = y_test\n",
    "\n",
    "models = [model_ft_sg,model_ft_cbow,model_w2v_sg,model_w2v_cbow]\n",
    "\n",
    "###############################################################################################################################\n",
    "\n",
    "models_names = [\"FastText_SG\",\"FastText_CBOW\",\"Word2vec_SG\",\"Word2vec_CBOW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file to save Results :\n",
    "results = open(\"../CODE/Results/Result_3CNN100.txt\",'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37398 37398 12466 12466\n",
      "Epoch 1/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.4241 - accuracy: 0.8021\n",
      "Epoch 2/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.2547 - accuracy: 0.8909\n",
      "Epoch 3/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.1445 - accuracy: 0.9375\n",
      "Epoch 4/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0957 - accuracy: 0.9556\n",
      "Epoch 5/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0770 - accuracy: 0.9625\n",
      "Epoch 6/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0703 - accuracy: 0.9651\n",
      "Epoch 7/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0670 - accuracy: 0.9660\n",
      "Epoch 8/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0604 - accuracy: 0.9683\n",
      "Epoch 9/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0582 - accuracy: 0.9692\n",
      "Epoch 10/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0571 - accuracy: 0.9689\n",
      "Epoch 11/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0609 - accuracy: 0.9683\n",
      "Epoch 12/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0546 - accuracy: 0.9702\n",
      "Epoch 13/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0545 - accuracy: 0.9699\n",
      "Epoch 14/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0565 - accuracy: 0.9698\n",
      "Epoch 15/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0560 - accuracy: 0.9698\n",
      "Epoch 16/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0537 - accuracy: 0.9709\n",
      "Epoch 17/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.0521 - accuracy: 0.9710\n",
      "Epoch 18/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0513 - accuracy: 0.9714\n",
      "Epoch 19/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0578 - accuracy: 0.9696\n",
      "Epoch 20/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0551 - accuracy: 0.9701\n",
      "Epoch 21/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0518 - accuracy: 0.9713\n",
      "Epoch 22/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0512 - accuracy: 0.9712\n",
      "Epoch 23/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0505 - accuracy: 0.9716\n",
      "Epoch 24/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0561 - accuracy: 0.9701\n",
      "Epoch 25/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0524 - accuracy: 0.9714\n",
      "Epoch 26/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0508 - accuracy: 0.9717\n",
      "Epoch 27/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0537 - accuracy: 0.9706\n",
      "Epoch 28/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0531 - accuracy: 0.9711\n",
      "Epoch 29/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0506 - accuracy: 0.9715\n",
      "Epoch 30/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0498 - accuracy: 0.9718\n",
      "Epoch 31/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0502 - accuracy: 0.9716\n",
      "Epoch 32/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0505 - accuracy: 0.9720\n",
      "Epoch 33/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0538 - accuracy: 0.9707\n",
      "Epoch 34/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.0528 - accuracy: 0.9711\n",
      "Epoch 35/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0516 - accuracy: 0.9716\n",
      "Epoch 36/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0530 - accuracy: 0.9710\n",
      "Epoch 37/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0502 - accuracy: 0.9719\n",
      "Epoch 38/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0499 - accuracy: 0.9721\n",
      "Epoch 39/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0505 - accuracy: 0.9718\n",
      "Epoch 40/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0505 - accuracy: 0.9718\n",
      "Epoch 41/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0520 - accuracy: 0.9714\n",
      "Epoch 42/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0506 - accuracy: 0.9717\n",
      "Epoch 43/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0495 - accuracy: 0.9721\n",
      "Epoch 44/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0495 - accuracy: 0.9718\n",
      "Epoch 45/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0497 - accuracy: 0.9717\n",
      "Epoch 46/100\n",
      "1169/1169 [==============================] - 469s 402ms/step - loss: 0.0542 - accuracy: 0.9712\n",
      "Epoch 47/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0505 - accuracy: 0.9717\n",
      "Epoch 48/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0529 - accuracy: 0.9714\n",
      "Epoch 49/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0524 - accuracy: 0.9715\n",
      "Epoch 50/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0504 - accuracy: 0.9717\n",
      "Epoch 51/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0494 - accuracy: 0.9721\n",
      "Epoch 52/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0494 - accuracy: 0.9722\n",
      "Epoch 53/100\n",
      "1169/1169 [==============================] - 469s 401ms/step - loss: 0.0508 - accuracy: 0.9720\n",
      "Epoch 54/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0522 - accuracy: 0.9719\n",
      "Epoch 55/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0505 - accuracy: 0.9719\n",
      "Epoch 56/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0494 - accuracy: 0.9722\n",
      "Epoch 57/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.0498 - accuracy: 0.9719\n",
      "Epoch 58/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0495 - accuracy: 0.9724\n",
      "Epoch 59/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0494 - accuracy: 0.9721\n",
      "Epoch 60/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0530 - accuracy: 0.9713\n",
      "Epoch 61/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0503 - accuracy: 0.9720\n",
      "Epoch 62/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0502 - accuracy: 0.9721\n",
      "Epoch 63/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0516 - accuracy: 0.9718\n",
      "Epoch 64/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0495 - accuracy: 0.9721\n",
      "Epoch 65/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0497 - accuracy: 0.9721\n",
      "Epoch 66/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0502 - accuracy: 0.9720\n",
      "Epoch 67/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0542 - accuracy: 0.9712\n",
      "Epoch 68/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0497 - accuracy: 0.9722\n",
      "Epoch 69/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0492 - accuracy: 0.9722\n",
      "Epoch 70/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0493 - accuracy: 0.9720\n",
      "Epoch 71/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0494 - accuracy: 0.9720\n",
      "Epoch 72/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0537 - accuracy: 0.9714\n",
      "Epoch 73/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0501 - accuracy: 0.9719\n",
      "Epoch 74/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0518 - accuracy: 0.9715\n",
      "Epoch 75/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0498 - accuracy: 0.9721\n",
      "Epoch 76/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0493 - accuracy: 0.9722\n",
      "Epoch 77/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0493 - accuracy: 0.9721\n",
      "Epoch 78/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0497 - accuracy: 0.9721\n",
      "Epoch 79/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0516 - accuracy: 0.9719\n",
      "Epoch 80/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0517 - accuracy: 0.9718\n",
      "Epoch 81/100\n",
      "1169/1169 [==============================] - 469s 401ms/step - loss: 0.0530 - accuracy: 0.9715\n",
      "Epoch 82/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0496 - accuracy: 0.9720\n",
      "Epoch 83/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0492 - accuracy: 0.9722\n",
      "Epoch 84/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0492 - accuracy: 0.9723\n",
      "Epoch 85/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0493 - accuracy: 0.9721\n",
      "Epoch 86/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0509 - accuracy: 0.9717\n",
      "Epoch 87/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0504 - accuracy: 0.9717\n",
      "Epoch 88/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0497 - accuracy: 0.9720\n",
      "Epoch 89/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0493 - accuracy: 0.9722\n",
      "Epoch 90/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0511 - accuracy: 0.9722\n",
      "Epoch 91/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0571 - accuracy: 0.9715\n",
      "Epoch 92/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0502 - accuracy: 0.9720\n",
      "Epoch 93/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0493 - accuracy: 0.9722\n",
      "Epoch 94/100\n",
      "1169/1169 [==============================] - 469s 401ms/step - loss: 0.0492 - accuracy: 0.9722\n",
      "Epoch 95/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0491 - accuracy: 0.9723\n",
      "Epoch 96/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0495 - accuracy: 0.9721\n",
      "Epoch 97/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0519 - accuracy: 0.9717\n",
      "Epoch 98/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0498 - accuracy: 0.9721\n",
      "Epoch 99/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0492 - accuracy: 0.9722\n",
      "Epoch 100/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0493 - accuracy: 0.9722\n",
      "INFO:tensorflow:Assets written to: ../Models/CNN_model_FastText_SG\\assets\n",
      "- finish -------------------------------------------------------------------- Train the CNN using : FastText_SG\n",
      "37398 37398 12466 12466\n",
      "Epoch 1/100\n",
      "1169/1169 [==============================] - 461s 394ms/step - loss: 0.4990 - accuracy: 0.7520\n",
      "Epoch 2/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.4074 - accuracy: 0.8122\n",
      "Epoch 3/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.3323 - accuracy: 0.8515\n",
      "Epoch 4/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.2529 - accuracy: 0.8894\n",
      "Epoch 5/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.1888 - accuracy: 0.9164\n",
      "Epoch 6/100\n",
      "1169/1169 [==============================] - 469s 401ms/step - loss: 0.1499 - accuracy: 0.9324\n",
      "Epoch 7/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.1258 - accuracy: 0.9419\n",
      "Epoch 8/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.1083 - accuracy: 0.9491\n",
      "Epoch 9/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.1026 - accuracy: 0.9507\n",
      "Epoch 10/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0904 - accuracy: 0.9562\n",
      "Epoch 11/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0902 - accuracy: 0.9571\n",
      "Epoch 12/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0827 - accuracy: 0.9596\n",
      "Epoch 13/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0780 - accuracy: 0.9616\n",
      "Epoch 14/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0751 - accuracy: 0.9625\n",
      "Epoch 15/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0727 - accuracy: 0.9633\n",
      "Epoch 16/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0764 - accuracy: 0.9634\n",
      "Epoch 17/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0677 - accuracy: 0.9658\n",
      "Epoch 18/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0648 - accuracy: 0.9665\n",
      "Epoch 19/100\n",
      "1169/1169 [==============================] - 469s 401ms/step - loss: 0.0707 - accuracy: 0.9652\n",
      "Epoch 20/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0654 - accuracy: 0.9665\n",
      "Epoch 21/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0656 - accuracy: 0.9671\n",
      "Epoch 22/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0666 - accuracy: 0.9663\n",
      "Epoch 23/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0606 - accuracy: 0.9683\n",
      "Epoch 24/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0627 - accuracy: 0.9677\n",
      "Epoch 25/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0603 - accuracy: 0.9686\n",
      "Epoch 26/100\n",
      "1169/1169 [==============================] - 470s 402ms/step - loss: 0.0602 - accuracy: 0.9687\n",
      "Epoch 27/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0623 - accuracy: 0.9682\n",
      "Epoch 28/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0586 - accuracy: 0.9687\n",
      "Epoch 29/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0640 - accuracy: 0.9684\n",
      "Epoch 30/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0597 - accuracy: 0.9692\n",
      "Epoch 31/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0566 - accuracy: 0.9698\n",
      "Epoch 32/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0662 - accuracy: 0.9681\n",
      "Epoch 33/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0581 - accuracy: 0.9694\n",
      "Epoch 34/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0600 - accuracy: 0.9692\n",
      "Epoch 35/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0539 - accuracy: 0.9705\n",
      "Epoch 36/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0603 - accuracy: 0.9692\n",
      "Epoch 37/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0574 - accuracy: 0.9692\n",
      "Epoch 38/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.0555 - accuracy: 0.9701\n",
      "Epoch 39/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.0555 - accuracy: 0.9703\n",
      "Epoch 40/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0588 - accuracy: 0.9695\n",
      "Epoch 41/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0555 - accuracy: 0.9703\n",
      "Epoch 42/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0601 - accuracy: 0.9695\n",
      "Epoch 43/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0520 - accuracy: 0.9714\n",
      "Epoch 44/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0541 - accuracy: 0.9702\n",
      "Epoch 45/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0592 - accuracy: 0.9691\n",
      "Epoch 46/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.0551 - accuracy: 0.9704\n",
      "Epoch 47/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0521 - accuracy: 0.9707\n",
      "Epoch 48/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0539 - accuracy: 0.9707\n",
      "Epoch 49/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0592 - accuracy: 0.9699\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0560 - accuracy: 0.9705\n",
      "Epoch 51/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.0552 - accuracy: 0.9705\n",
      "Epoch 52/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0508 - accuracy: 0.9716\n",
      "Epoch 53/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0623 - accuracy: 0.9692\n",
      "Epoch 54/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0534 - accuracy: 0.9709\n",
      "Epoch 55/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0524 - accuracy: 0.9712\n",
      "Epoch 56/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0559 - accuracy: 0.9704\n",
      "Epoch 57/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0552 - accuracy: 0.9709\n",
      "Epoch 58/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0541 - accuracy: 0.9710\n",
      "Epoch 59/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0537 - accuracy: 0.9710\n",
      "Epoch 60/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0552 - accuracy: 0.9710\n",
      "Epoch 61/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0512 - accuracy: 0.9716\n",
      "Epoch 62/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0510 - accuracy: 0.9715\n",
      "Epoch 63/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0529 - accuracy: 0.9713\n",
      "Epoch 64/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0585 - accuracy: 0.9701\n",
      "Epoch 65/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0525 - accuracy: 0.9713\n",
      "Epoch 66/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0546 - accuracy: 0.9711\n",
      "Epoch 67/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0513 - accuracy: 0.9715\n",
      "Epoch 68/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0535 - accuracy: 0.9710\n",
      "Epoch 69/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0517 - accuracy: 0.9716\n",
      "Epoch 70/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0504 - accuracy: 0.9719\n",
      "Epoch 71/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0548 - accuracy: 0.9709\n",
      "Epoch 72/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0520 - accuracy: 0.9715\n",
      "Epoch 73/100\n",
      "1169/1169 [==============================] - 468s 401ms/step - loss: 0.0523 - accuracy: 0.9714\n",
      "Epoch 74/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0562 - accuracy: 0.9706\n",
      "Epoch 75/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0531 - accuracy: 0.9713\n",
      "Epoch 76/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0527 - accuracy: 0.9716\n",
      "Epoch 77/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0599 - accuracy: 0.9706\n",
      "Epoch 78/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0517 - accuracy: 0.9711\n",
      "Epoch 79/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0537 - accuracy: 0.9713\n",
      "Epoch 80/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0522 - accuracy: 0.9712\n",
      "Epoch 81/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0539 - accuracy: 0.9712\n",
      "Epoch 82/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0516 - accuracy: 0.9716\n",
      "Epoch 83/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0531 - accuracy: 0.9709\n",
      "Epoch 84/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0578 - accuracy: 0.9711\n",
      "Epoch 85/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0511 - accuracy: 0.9717\n",
      "Epoch 86/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0511 - accuracy: 0.9716\n",
      "Epoch 87/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0571 - accuracy: 0.9707\n",
      "Epoch 88/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0527 - accuracy: 0.9715\n",
      "Epoch 89/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0510 - accuracy: 0.9717\n",
      "Epoch 90/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0504 - accuracy: 0.9719\n",
      "Epoch 91/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0563 - accuracy: 0.9709\n",
      "Epoch 92/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0503 - accuracy: 0.9717\n",
      "Epoch 93/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0499 - accuracy: 0.9721\n",
      "Epoch 94/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0508 - accuracy: 0.9720\n",
      "Epoch 95/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0557 - accuracy: 0.9706\n",
      "Epoch 96/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0574 - accuracy: 0.9708\n",
      "Epoch 97/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0504 - accuracy: 0.9720\n",
      "Epoch 98/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0513 - accuracy: 0.9715\n",
      "Epoch 99/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0567 - accuracy: 0.9705\n",
      "Epoch 100/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0507 - accuracy: 0.9720\n",
      "INFO:tensorflow:Assets written to: ../Models/CNN_model_FastText_CBOW\\assets\n",
      "- finish -------------------------------------------------------------------- Train the CNN using : FastText_CBOW\n",
      "37398 37398 12466 12466\n",
      "Epoch 1/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.4224 - accuracy: 0.8004\n",
      "Epoch 2/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.2579 - accuracy: 0.8886\n",
      "Epoch 3/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.1467 - accuracy: 0.9353\n",
      "Epoch 4/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0979 - accuracy: 0.9543\n",
      "Epoch 5/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0755 - accuracy: 0.9623\n",
      "Epoch 6/100\n",
      "1169/1169 [==============================] - 468s 401ms/step - loss: 0.0723 - accuracy: 0.9641\n",
      "Epoch 7/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0672 - accuracy: 0.9663\n",
      "Epoch 8/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0605 - accuracy: 0.9685\n",
      "Epoch 9/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0582 - accuracy: 0.9691\n",
      "Epoch 10/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0573 - accuracy: 0.9695\n",
      "Epoch 11/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0583 - accuracy: 0.9692\n",
      "Epoch 12/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0556 - accuracy: 0.9701\n",
      "Epoch 13/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0569 - accuracy: 0.9693\n",
      "Epoch 14/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0570 - accuracy: 0.9697\n",
      "Epoch 15/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0547 - accuracy: 0.9701\n",
      "Epoch 16/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0520 - accuracy: 0.9713\n",
      "Epoch 17/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0539 - accuracy: 0.9709\n",
      "Epoch 18/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0562 - accuracy: 0.9701\n",
      "Epoch 19/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0535 - accuracy: 0.9705\n",
      "Epoch 20/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0521 - accuracy: 0.9712\n",
      "Epoch 21/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0516 - accuracy: 0.9713\n",
      "Epoch 22/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0546 - accuracy: 0.9706\n",
      "Epoch 23/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0531 - accuracy: 0.9708\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0533 - accuracy: 0.9711\n",
      "Epoch 25/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0537 - accuracy: 0.9708\n",
      "Epoch 26/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0513 - accuracy: 0.9712\n",
      "Epoch 27/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0505 - accuracy: 0.9715\n",
      "Epoch 28/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.0503 - accuracy: 0.9717\n",
      "Epoch 29/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0506 - accuracy: 0.9716\n",
      "Epoch 30/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0505 - accuracy: 0.9719\n",
      "Epoch 31/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0550 - accuracy: 0.9706\n",
      "Epoch 32/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0533 - accuracy: 0.9709\n",
      "Epoch 33/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0499 - accuracy: 0.9721\n",
      "Epoch 34/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0498 - accuracy: 0.9720\n",
      "Epoch 35/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0504 - accuracy: 0.9716\n",
      "Epoch 36/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0558 - accuracy: 0.9712\n",
      "Epoch 37/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0534 - accuracy: 0.9713\n",
      "Epoch 38/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0497 - accuracy: 0.9721\n",
      "Epoch 39/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0496 - accuracy: 0.9721\n",
      "Epoch 40/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0496 - accuracy: 0.9723\n",
      "Epoch 41/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0539 - accuracy: 0.9716\n",
      "Epoch 42/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0515 - accuracy: 0.9717\n",
      "Epoch 43/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0526 - accuracy: 0.9715\n",
      "Epoch 44/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0503 - accuracy: 0.9719\n",
      "Epoch 45/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0498 - accuracy: 0.9721\n",
      "Epoch 46/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0501 - accuracy: 0.9723\n",
      "Epoch 47/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0499 - accuracy: 0.9721\n",
      "Epoch 48/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0503 - accuracy: 0.9722\n",
      "Epoch 49/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0531 - accuracy: 0.9715\n",
      "Epoch 50/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0509 - accuracy: 0.9719\n",
      "Epoch 51/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0524 - accuracy: 0.9717\n",
      "Epoch 52/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0501 - accuracy: 0.9718\n",
      "Epoch 53/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0516 - accuracy: 0.9717\n",
      "Epoch 54/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0514 - accuracy: 0.9719\n",
      "Epoch 55/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0503 - accuracy: 0.9718\n",
      "Epoch 56/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0494 - accuracy: 0.9721\n",
      "Epoch 57/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0496 - accuracy: 0.9721\n",
      "Epoch 58/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0497 - accuracy: 0.9721\n",
      "Epoch 59/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0511 - accuracy: 0.9717\n",
      "Epoch 60/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0525 - accuracy: 0.9718\n",
      "Epoch 61/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0505 - accuracy: 0.9720\n",
      "Epoch 62/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0514 - accuracy: 0.9717\n",
      "Epoch 63/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0505 - accuracy: 0.9720\n",
      "Epoch 64/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0493 - accuracy: 0.9722\n",
      "Epoch 65/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0494 - accuracy: 0.9723\n",
      "Epoch 66/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0494 - accuracy: 0.9723\n",
      "Epoch 67/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0528 - accuracy: 0.9717\n",
      "Epoch 68/100\n",
      "1169/1169 [==============================] - 468s 401ms/step - loss: 0.0513 - accuracy: 0.9718\n",
      "Epoch 69/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0498 - accuracy: 0.9722\n",
      "Epoch 70/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0512 - accuracy: 0.9718\n",
      "Epoch 71/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0502 - accuracy: 0.9719\n",
      "Epoch 72/100\n",
      "1169/1169 [==============================] - 469s 401ms/step - loss: 0.0494 - accuracy: 0.9723\n",
      "Epoch 73/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0493 - accuracy: 0.9721\n",
      "Epoch 74/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0493 - accuracy: 0.9722\n",
      "Epoch 75/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0527 - accuracy: 0.9717\n",
      "Epoch 76/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0494 - accuracy: 0.9721\n",
      "Epoch 77/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0560 - accuracy: 0.9717\n",
      "Epoch 78/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0502 - accuracy: 0.9722\n",
      "Epoch 79/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0506 - accuracy: 0.9721\n",
      "Epoch 80/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0498 - accuracy: 0.9721\n",
      "Epoch 81/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0493 - accuracy: 0.9723\n",
      "Epoch 82/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0493 - accuracy: 0.9723\n",
      "Epoch 83/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0495 - accuracy: 0.9722\n",
      "Epoch 84/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0528 - accuracy: 0.9720\n",
      "Epoch 85/100\n",
      "1169/1169 [==============================] - 469s 401ms/step - loss: 0.0493 - accuracy: 0.9724\n",
      "Epoch 86/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0498 - accuracy: 0.9721\n",
      "Epoch 87/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0544 - accuracy: 0.9716\n",
      "Epoch 88/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0495 - accuracy: 0.9721\n",
      "Epoch 89/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0497 - accuracy: 0.9722\n",
      "Epoch 90/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0493 - accuracy: 0.9724\n",
      "Epoch 91/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0492 - accuracy: 0.9722\n",
      "Epoch 92/100\n",
      "1169/1169 [==============================] - 469s 401ms/step - loss: 0.0540 - accuracy: 0.9717\n",
      "Epoch 93/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0506 - accuracy: 0.9718\n",
      "Epoch 94/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0491 - accuracy: 0.9724\n",
      "Epoch 95/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0491 - accuracy: 0.9723\n",
      "Epoch 96/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0494 - accuracy: 0.9722\n",
      "Epoch 97/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0519 - accuracy: 0.9720\n",
      "Epoch 98/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0536 - accuracy: 0.9715\n",
      "Epoch 99/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0494 - accuracy: 0.9721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0493 - accuracy: 0.9723\n",
      "INFO:tensorflow:Assets written to: ../Models/CNN_model_Word2vec_SG\\assets\n",
      "- finish -------------------------------------------------------------------- Train the CNN using : Word2vec_SG\n",
      "37398 37398 12466 12466\n",
      "Epoch 1/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.4803 - accuracy: 0.7651\n",
      "Epoch 2/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.3803 - accuracy: 0.8268\n",
      "Epoch 3/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.2940 - accuracy: 0.8727\n",
      "Epoch 4/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.2085 - accuracy: 0.9102\n",
      "Epoch 5/100\n",
      "1169/1169 [==============================] - 462s 395ms/step - loss: 0.1571 - accuracy: 0.9311\n",
      "Epoch 6/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.1227 - accuracy: 0.9427\n",
      "Epoch 7/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.1065 - accuracy: 0.9500\n",
      "Epoch 8/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0996 - accuracy: 0.9528\n",
      "Epoch 9/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0908 - accuracy: 0.9565\n",
      "Epoch 10/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0827 - accuracy: 0.9592\n",
      "Epoch 11/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0790 - accuracy: 0.9607\n",
      "Epoch 12/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0767 - accuracy: 0.9623\n",
      "Epoch 13/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0697 - accuracy: 0.9647\n",
      "Epoch 14/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0701 - accuracy: 0.9649\n",
      "Epoch 15/100\n",
      "1169/1169 [==============================] - 465s 397ms/step - loss: 0.0693 - accuracy: 0.9658\n",
      "Epoch 16/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0654 - accuracy: 0.9657\n",
      "Epoch 17/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0661 - accuracy: 0.9672\n",
      "Epoch 18/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0636 - accuracy: 0.9673\n",
      "Epoch 19/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0602 - accuracy: 0.9687\n",
      "Epoch 20/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0647 - accuracy: 0.9671\n",
      "Epoch 21/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0614 - accuracy: 0.9682\n",
      "Epoch 22/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0573 - accuracy: 0.9694\n",
      "Epoch 23/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0625 - accuracy: 0.9678\n",
      "Epoch 24/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0587 - accuracy: 0.9692\n",
      "Epoch 25/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0557 - accuracy: 0.9704\n",
      "Epoch 26/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0580 - accuracy: 0.9696\n",
      "Epoch 27/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0588 - accuracy: 0.9692\n",
      "Epoch 28/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0550 - accuracy: 0.9702\n",
      "Epoch 29/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0554 - accuracy: 0.9700\n",
      "Epoch 30/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0609 - accuracy: 0.9695\n",
      "Epoch 31/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0556 - accuracy: 0.9702\n",
      "Epoch 32/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0529 - accuracy: 0.9709\n",
      "Epoch 33/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0636 - accuracy: 0.9685\n",
      "Epoch 34/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0555 - accuracy: 0.9705\n",
      "Epoch 35/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0573 - accuracy: 0.9701\n",
      "Epoch 36/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0550 - accuracy: 0.9704\n",
      "Epoch 37/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0517 - accuracy: 0.9714\n",
      "Epoch 38/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0509 - accuracy: 0.9716\n",
      "Epoch 39/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0591 - accuracy: 0.9699\n",
      "Epoch 40/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0542 - accuracy: 0.9707\n",
      "Epoch 41/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0543 - accuracy: 0.9711\n",
      "Epoch 42/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0550 - accuracy: 0.9706\n",
      "Epoch 43/100\n",
      "1169/1169 [==============================] - 468s 400ms/step - loss: 0.0513 - accuracy: 0.9716\n",
      "Epoch 44/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0512 - accuracy: 0.9717\n",
      "Epoch 45/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0512 - accuracy: 0.9717\n",
      "Epoch 46/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0644 - accuracy: 0.9696\n",
      "Epoch 47/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0525 - accuracy: 0.9714\n",
      "Epoch 48/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0511 - accuracy: 0.9717\n",
      "Epoch 49/100\n",
      "1169/1169 [==============================] - 469s 401ms/step - loss: 0.0512 - accuracy: 0.9714\n",
      "Epoch 50/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0546 - accuracy: 0.9712\n",
      "Epoch 51/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0522 - accuracy: 0.9712\n",
      "Epoch 52/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0544 - accuracy: 0.9711\n",
      "Epoch 53/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0549 - accuracy: 0.9709\n",
      "Epoch 54/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0524 - accuracy: 0.9713\n",
      "Epoch 55/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0539 - accuracy: 0.9712\n",
      "Epoch 56/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0502 - accuracy: 0.9717\n",
      "Epoch 57/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0505 - accuracy: 0.9719\n",
      "Epoch 58/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0540 - accuracy: 0.9709\n",
      "Epoch 59/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0565 - accuracy: 0.9703\n",
      "Epoch 60/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0537 - accuracy: 0.9711\n",
      "Epoch 61/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0506 - accuracy: 0.9719\n",
      "Epoch 62/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0526 - accuracy: 0.9714\n",
      "Epoch 63/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0526 - accuracy: 0.9717\n",
      "Epoch 64/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0507 - accuracy: 0.9719\n",
      "Epoch 65/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0558 - accuracy: 0.9711\n",
      "Epoch 66/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0512 - accuracy: 0.9715\n",
      "Epoch 67/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0507 - accuracy: 0.9718\n",
      "Epoch 68/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0503 - accuracy: 0.9717\n",
      "Epoch 69/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0511 - accuracy: 0.9718\n",
      "Epoch 70/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0570 - accuracy: 0.9706\n",
      "Epoch 71/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0511 - accuracy: 0.9718\n",
      "Epoch 72/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0497 - accuracy: 0.9720\n",
      "Epoch 73/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0495 - accuracy: 0.9719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0502 - accuracy: 0.9717\n",
      "Epoch 75/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0563 - accuracy: 0.9711\n",
      "Epoch 76/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0564 - accuracy: 0.9708\n",
      "Epoch 77/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0525 - accuracy: 0.9715\n",
      "Epoch 78/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0501 - accuracy: 0.9720\n",
      "Epoch 79/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0509 - accuracy: 0.9717\n",
      "Epoch 80/100\n",
      "1169/1169 [==============================] - 467s 399ms/step - loss: 0.0565 - accuracy: 0.9708\n",
      "Epoch 81/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0526 - accuracy: 0.9714\n",
      "Epoch 82/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0503 - accuracy: 0.9718\n",
      "Epoch 83/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0509 - accuracy: 0.9717\n",
      "Epoch 84/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0535 - accuracy: 0.9713\n",
      "Epoch 85/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0539 - accuracy: 0.9715\n",
      "Epoch 86/100\n",
      "1169/1169 [==============================] - 465s 398ms/step - loss: 0.0533 - accuracy: 0.9715\n",
      "Epoch 87/100\n",
      "1169/1169 [==============================] - 467s 400ms/step - loss: 0.0498 - accuracy: 0.9720\n",
      "Epoch 88/100\n",
      "1169/1169 [==============================] - 466s 399ms/step - loss: 0.0499 - accuracy: 0.9720\n",
      "Epoch 89/100\n",
      "1169/1169 [==============================] - 466s 398ms/step - loss: 0.0501 - accuracy: 0.9719\n",
      "Epoch 90/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0498 - accuracy: 0.9721\n",
      "Epoch 91/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0572 - accuracy: 0.9709\n",
      "Epoch 92/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0526 - accuracy: 0.9718\n",
      "Epoch 93/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0511 - accuracy: 0.9718\n",
      "Epoch 94/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0494 - accuracy: 0.9720\n",
      "Epoch 95/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0496 - accuracy: 0.9720\n",
      "Epoch 96/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0497 - accuracy: 0.9720\n",
      "Epoch 97/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0559 - accuracy: 0.9710\n",
      "Epoch 98/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0531 - accuracy: 0.9711\n",
      "Epoch 99/100\n",
      "1169/1169 [==============================] - 463s 396ms/step - loss: 0.0532 - accuracy: 0.9713\n",
      "Epoch 100/100\n",
      "1169/1169 [==============================] - 464s 397ms/step - loss: 0.0498 - accuracy: 0.9720\n",
      "INFO:tensorflow:Assets written to: ../Models/CNN_model_Word2vec_CBOW\\assets\n",
      "- finish -------------------------------------------------------------------- Train the CNN using : Word2vec_CBOW\n"
     ]
    }
   ],
   "source": [
    "for model, name in zip(models, models_names) :\n",
    "    info = \"Train the CNN using : \"+name\n",
    "    print(len(X_train),len(y_train),len(X_test),len(y_test))\n",
    "    model.fit(X_train, np.array(y_train), epochs = epoch, verbose=1)\n",
    "    model.save(\"../Models/CNN_model_\"+name)\n",
    "    evaluate_model(y_test,predict(model,X_test,y_test), results ,info )\n",
    "    print(\"- finish -------------------------------------------------------------------- \"+info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close file \n",
    "results.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001682F55F280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "CNN_model_FastText_SG = load_model('../Models/CNN_model_Word2vec_CBOW')\n",
    "\n",
    "\n",
    "#text = [\"ياخي حالة ياخي\"]\n",
    "text = [\" قلب \"]\n",
    "#text = [\"مليحة \"]\n",
    "text = pad_sequences(tokenizer.texts_to_sequences(text),maxlen = max_len_data)\n",
    "\n",
    "prediction = CNN_model_FastText_SG.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37465876]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37465876]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
