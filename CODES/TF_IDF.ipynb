{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"In this paper, we address the lack of resources for opinion and emotion analysis related to North African dialects, targeting Algerian dialect. We present TWIFIL (TWItter proFILing) a collaborative annotation platform for crowdsourcing annotation of tweets at differentlevels of granularity. The plateform allowed the creation of the largest Algerian dialect dataset annotated for both sentiment (9,000tweets), emotion (about 5,000 tweets) and extra-linguistic information including author profiling (age and gender). The annotation resulted also in the creation of the largest Algerien dialect subjectivity lexicon of about 9,000 entries which can constitute a valuable resources for the development of future NLP applications for Algerian dialect. To test the validity of the dataset, a set of deep learning experiments were conducted to classify a given tweet as positive, negative or neutral. We discuss our results and provide an error analysis to better identify classification errors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ' , sentences[i])\n",
    "    review = review.lower()\n",
    "    #review = review.split()\n",
    "   # review = [wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in this paper we address the lack of resources for opinion and emotion analysis related to north african dialects targeting algerian dialect',\n",
       " 'we present twifil twitter profiling a collaborative annotation platform for crowdsourcing annotation of tweets at differentlevels of granularity',\n",
       " 'the plateform allowed the creation of the largest algerian dialect dataset annotated for both sentiment tweets emotion about tweets and extra linguistic information including author profiling age and gender',\n",
       " 'the annotation resulted also in the creation of the largest algerien dialect subjectivity lexicon of about entries which can constitute a valuable resources for the development of future nlp applications for algerian dialect',\n",
       " 'to test the validity of the dataset a set of deep learning experiments were conducted to classify a given tweet as positive negative or neutral',\n",
       " 'we discuss our results and provide an error analysis to better identify classification errors',\n",
       " 'i n   t h i s   p a p e r     w e   a d d r e s s   t h e   l a c k   o f   r e s o u r c e s   f o r   o p i n i o n   a n d   e m o t i o n   a n a l y s i s   r e l a t e d   t o   n o r t h   a f r i c a n   d i a l e c t s     t a r g e t i n g   a l g e r i a n   d i a l e c t  ',\n",
       " 'w e   p r e s e n t   t w i f i l     t w i t t e r   p r o f i l i n g     a   c o l l a b o r a t i v e   a n n o t a t i o n   p l a t f o r m   f o r   c r o w d s o u r c i n g   a n n o t a t i o n   o f   t w e e t s   a t   d i f f e r e n t l e v e l s   o f   g r a n u l a r i t y  ',\n",
       " 't h e   p l a t e f o r m   a l l o w e d   t h e   c r e a t i o n   o f   t h e   l a r g e s t   a l g e r i a n   d i a l e c t   d a t a s e t   a n n o t a t e d   f o r   b o t h   s e n t i m e n t               t w e e t s       e m o t i o n     a b o u t               t w e e t s     a n d   e x t r a   l i n g u i s t i c   i n f o r m a t i o n   i n c l u d i n g   a u t h o r   p r o f i l i n g     a g e   a n d   g e n d e r    ',\n",
       " 't h e   a n n o t a t i o n   r e s u l t e d   a l s o   i n   t h e   c r e a t i o n   o f   t h e   l a r g e s t   a l g e r i e n   d i a l e c t   s u b j e c t i v i t y   l e x i c o n   o f   a b o u t               e n t r i e s   w h i c h   c a n   c o n s t i t u t e   a   v a l u a b l e   r e s o u r c e s   f o r   t h e   d e v e l o p m e n t   o f   f u t u r e   n l p   a p p l i c a t i o n s   f o r   a l g e r i a n   d i a l e c t  ',\n",
       " 't o   t e s t   t h e   v a l i d i t y   o f   t h e   d a t a s e t     a   s e t   o f   d e e p   l e a r n i n g   e x p e r i m e n t s   w e r e   c o n d u c t e d   t o   c l a s s i f y   a   g i v e n   t w e e t   a s   p o s i t i v e     n e g a t i v e   o r   n e u t r a l  ',\n",
       " 'w e   d i s c u s s   o u r   r e s u l t s   a n d   p r o v i d e   a n   e r r o r   a n a l y s i s   t o   b e t t e r   i d e n t i f y   c l a s s i f i c a t i o n   e r r o r s  ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer()\n",
    "x = cv.fit_transform(corpus).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.24156797 0.24156797 ... 0.18326237 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.18972137 0.         0.        ]\n",
      " [0.1627462  0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
