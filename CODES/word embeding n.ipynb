{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ffaea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc0dc8",
   "metadata": {},
   "source": [
    " #READ DATA\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8818dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('../Data/cleaned_data1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d603839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"../DATA/cleaned_data1.csv\", names=[\"tweet\", \"class\"]).iloc[2:,:]\n",
    "dataframe[\"class\"] = np.where(dataframe[\"class\"] == \"Positive\",1,0)\n",
    "dataframe = dataframe.sample(frac = 1)\n",
    "x= dataframe['tweet'].apply(lambda x : str(x).split()).to_list()\n",
    "y = dataframe['class'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9bb6f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   tweet  class\n",
      "19824  الكتاب مقالات نشرت لاحمد حلمي يستحق ان يشتري ل...      0\n",
      "22551  جاوبني حفيظ عرض ب مليون اورو زايد اللاعب مانقا...      0\n",
      "16435  اعلاناتهم المدفوعه بملايين الدولارات صحف اميرك...      0\n",
      "19788   اتحدي اي واحد يشتري مره اولي يرجع ههه ممتازه مره      0\n",
      "1136                                              التقشف      0\n",
      "...                                                  ...    ...\n",
      "39133  افضل منتجع شرم ذهبت الي المنتجع و كان نظيفا جد...      1\n",
      "24726  روايه ضعيفه اخر كام صفحه اللي قصه حقيقيه اصلا ...      0\n",
      "38433  منتجع رايع جدا المنتجع رايع رايع رايع قضينا اي...      1\n",
      "47365  ابطال اسيا خسر الاتحاد سونغنام جده ورجع بالكاس...      1\n",
      "18816  الكتاب اقل توقعاتي لموهبه احمد مراد فهو بحق مب...      0\n",
      "\n",
      "[49864 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c89521c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['جاوبني', 'حفيظ', 'عرض', 'ب', 'مليون', 'اورو', 'زايد', 'اللاعب', 'مانقالا', 'حسب', 'الصحف', 'فيشاي', 'يريد', 'اكثر', 'مليون', 'اورو', 'سيبيعه', 'بهذالسعر', 'رايك', 'العلم', 'اللاعب', 'يبلغ', 'العمر', 'سنه']\n"
     ]
    }
   ],
   "source": [
    "print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4487bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,y_test= train_test_split(x,y,test_size=0.25,random_state=42 , stratify=y)  #same random state \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c7a4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 300    # Word vector dimensionality  \n",
    "window_context = 50          # Context window size                                                                                    \n",
    "min_word_count = 2   # Minimum word count                        \n",
    "sample = 1e-3   # Downsample setting for frequent words\n",
    "epoch = 10# Number of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b5c9a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etudiant\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'نحبك': ['بنحبك', 'نحبوك', 'نحبو', 'نحبكم', 'يحبك'], 'افضل': ['هافضل', 'وافضل', 'افضضل', 'لافضل', 'فسافضل']}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "# sg decides whether to use the skip-gram model (1) or CBOW (0)\n",
    "ft_model_sg = FastText(sentences=x, window=window_context, vector_size=vec_size, \n",
    "                    min_count=min_word_count,sample=sample, sg=1, epochs=epoch)\n",
    "                                 \n",
    "\n",
    "\n",
    "\n",
    "# view similar words based on gensim's FastText model\n",
    "similar_words_sg = {search_term: [item[0] for item in ft_model_sg.wv.most_similar([search_term], topn=5)]\n",
    "                  for search_term in ['نحبك','افضل']}\n",
    "print(similar_words_sg) \n",
    "#epoch = 2 # Number of epochs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e601f",
   "metadata": {},
   "source": [
    "# Savethemodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8566fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_sg.save(\"./EmbeddingModels/ft_model_sg.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cbb2330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'نحبك': ['جسدك', 'تهبك', 'غضبك', 'بقلبك', 'قلبك'], 'افضل': ['افضضل', 'كافضل', 'فافضل', 'فسافضل', 'هفضل']}\n"
     ]
    }
   ],
   "source": [
    "ft_model_cbow = FastText(sentences=x, window=window_context, vector_size=vec_size, \n",
    "                    min_count=min_word_count,sample=sample, sg=0, epochs=epoch)\n",
    "similar_words_cbow = {search_term: [item[0] for item in ft_model_cbow.wv.most_similar([search_term], topn=5)]\n",
    "                  for search_term in ['نحبك','افضل']}\n",
    "print(similar_words_cbow) \n",
    "\n",
    "#epoch = 10# Number of epochs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "223b1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_cbow.save(\"./EmbeddingModels/ft_model_cbow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e008f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71330374\n",
      "0.32955176\n",
      "0.04373499\n",
      "0.13556601\n"
     ]
    }
   ],
   "source": [
    "print(ft_model_sg.wv.similarity(w1='نحبو', w2='نحبك'))\n",
    "print(ft_model_sg.wv.similarity(w1='فضل', w2='فسافضل'))\n",
    "print(ft_model_sg.wv.similarity(w1='افضل', w2='نموتو'))\n",
    "print(ft_model_sg.wv.similarity(w1='سكر', w2='افضل'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c725d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76219755\n",
      "0.91874635\n",
      "0.8537128\n",
      "0.87432224\n"
     ]
    }
   ],
   "source": [
    "print(ft_model_cbow.wv.similarity(w1='نحبو', w2='نحبك'))\n",
    "print(ft_model_cbow.wv.similarity(w1='ضل', w2='افضل'))\n",
    "print(ft_model_cbow.wv.similarity(w1='نعشق', w2='نحبك'))\n",
    "print(ft_model_cbow.wv.similarity(w1='نحبك', w2='غضبك'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7281765",
   "metadata": {},
   "source": [
    "# Word2vec : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fce12f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc28247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'نحبك': ['نحبوك', 'يحفضك', 'برافوو', 'بركا', 'طلتك'], 'افضل': ['بالمانيا', 'بكثير', 'فالخبر', 'وذوقك', 'شابهه']}\n",
      "{'نحبك': ['وهره', 'مناظله', 'السهريه', 'بتوفيق', 'معذبهم'], 'افضل': ['الافضل', 'بكثير', 'وافضل', 'بافضل', 'كازا']}\n"
     ]
    }
   ],
   "source": [
    "# sg decides whether to use the skip-gram model (1) or CBOW (0)\n",
    "w2v_model_sg = Word2Vec(sentences=x, window=window_context, vector_size=vec_size, \n",
    "                    min_count=min_word_count,sample=sample, sg=1, epochs=epoch)\n",
    "\n",
    "\n",
    "w2v_model_cbow = Word2Vec(sentences=x, window=window_context, vector_size=vec_size, \n",
    "                    min_count=min_word_count,sample=sample, sg=0, epochs=epoch)\n",
    "\n",
    "\n",
    "# view similar words based on gensim's Word2vec model\n",
    "similar_words_sg = {search_term: [item[0] for item in w2v_model_sg.wv.most_similar([search_term], topn=5)]\n",
    "                  for search_term in  ['نحبك','افضل']}\n",
    "print(similar_words_sg) \n",
    "\n",
    "similar_words_cbow = {search_term: [item[0] for item in w2v_model_cbow.wv.most_similar([search_term], topn=5)]\n",
    "                  for search_term in['نحبك','افضل']}\n",
    "print(similar_words_cbow) \n",
    "#epoch = 10 # Number of epochs \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0e62bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_sg.save(\"./EmbeddingModels/w2v_model_sg.model\")\n",
    "w2v_model_cbow.save(\"./EmbeddingModels/w2v_model_cbow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7170f106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('نحبوك', 0.7452232241630554),\n",
       " ('يحفضك', 0.722109854221344),\n",
       " ('برافوو', 0.7148568630218506),\n",
       " ('بركا', 0.7112698554992676),\n",
       " ('طلتك', 0.710512101650238),\n",
       " ('بكلهم', 0.7100936770439148),\n",
       " ('نشالله', 0.7097424864768982),\n",
       " ('السهريه', 0.707128643989563),\n",
       " ('بردتلي', 0.7070162892341614),\n",
       " ('ومحله', 0.7067701816558838)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_sg.wv.most_similar(positive=\"نحبك\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7da93e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('الافضل', 0.7576339244842529),\n",
       " ('بكثير', 0.6234630942344666),\n",
       " ('وافضل', 0.5824649930000305),\n",
       " ('بافضل', 0.5716922283172607),\n",
       " ('كازا', 0.5456104874610901),\n",
       " ('المعتاد', 0.5301099419593811),\n",
       " ('البندقيه', 0.5296929478645325),\n",
       " ('هاوس', 0.5228652954101562),\n",
       " ('باليرميتانو', 0.5206665396690369),\n",
       " ('شاروخان', 0.5204638242721558)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_cbow.wv.most_similar(positive=\"افضل\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43a725b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size, model):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model.wv[word].reshape((1, size))\n",
    "            count += 1\n",
    "        except KeyError: # handling the case where the token is not in vocabulary\n",
    "            \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "564b799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(data, vec_size, model):\n",
    "    arrays = np.zeros((len(data), vec_size))\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        arrays[i,:] = word_vector(data[i], vec_size , model)\n",
    "\n",
    "    result = pd.DataFrame(arrays)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d4d4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ft_sg = get_matrix(x_train,vec_size,ft_model_sg)\n",
    "x_test_ft_sg = get_matrix(x_test,vec_size,ft_model_sg)\n",
    "\n",
    "x_train_ft_cbow = get_matrix(x_train,vec_size,ft_model_cbow)\n",
    "x_test_ft_cbow = get_matrix(x_test,vec_size,ft_model_cbow)\n",
    "\n",
    "x_train_w2v_sg = get_matrix(x_train,vec_size,w2v_model_sg)\n",
    "x_test_w2v_sg = get_matrix(x_test,vec_size,w2v_model_sg)\n",
    "\n",
    "x_train_w2v_cbow = get_matrix(x_train,vec_size,w2v_model_cbow)\n",
    "x_test_w2v_cbow = get_matrix(x_test,vec_size,w2v_model_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e725e29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train  using FastText_cbow : (37398, 300)\n",
      "X_test   using FastText_cbow : (12466, 300)\n",
      "X_train  using FastText_cbow : (37398, 300)\n",
      "X_test   using FastText_cbow : (12466, 300)\n",
      "X_train using FastText_cbow : (37398, 300)\n",
      "X_test  using FastText_cbow : (12466, 300)\n",
      "X_train using FastText_cbow : (37398, 300)\n",
      "X_test  using FastText_cbow : (12466, 300)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train  using FastText_cbow : {x_train_ft_cbow.shape}\")\n",
    "print(f\"X_test   using FastText_cbow : {x_test_ft_cbow.shape}\")\n",
    "\n",
    "print(f\"X_train  using FastText_cbow : {x_train_ft_cbow.shape}\")\n",
    "print(f\"X_test   using FastText_cbow : {x_test_ft_cbow.shape}\")\n",
    "\n",
    "print(f\"X_train using FastText_cbow : {x_train_ft_cbow.shape}\")\n",
    "print(f\"X_test  using FastText_cbow : {x_test_ft_cbow.shape}\")\n",
    "\n",
    "print(f\"X_train using FastText_cbow : {x_train_ft_cbow.shape}\")\n",
    "print(f\"X_test  using FastText_cbow : {x_test_ft_cbow.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca21de",
   "metadata": {},
   "source": [
    "# Training the model : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f05bea8",
   "metadata": {},
   "source": [
    "## SVM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c4a30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "    # classify using support vector classifier\n",
    "    svm = svm.SVC(kernel = 'linear', probability=True)\n",
    "\n",
    "    # fit the SVC model based on the given training data\n",
    "    prob = svm.fit(x_train, y_train).predict_proba(x_test)\n",
    "\n",
    "    # perform classification and prediction on samples in x_test\n",
    "    y_pred_svm = svm.predict(x_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred_svm) * 100 \n",
    "    report = classification_report(y_test, y_pred_svm)\n",
    "    \n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3002185",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_ft_sg,   report_ft_sg     = svm(x_train_ft_sg,x_test_ft_sg,y_train,y_test)\n",
    "accuracy_ft_cbow, report_ft_cbow   = svm(x_train_ft_cbow,x_test_ft_cbow,y_train,y_test)\n",
    "\n",
    "accuracy_w2v_sg,   report_w2v_sg   = svm(x_train_w2v_sg,x_test_w2v_sg,y_train,y_test)\n",
    "accuracy_w2v_cbow, report_w2v_cbow = svm(x_train_w2v_cbow,x_test_w2v_cbow,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9f97aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "FastText_sg accuracy : 84.1649286058078 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      6233\n",
      "           1       0.86      0.82      0.84      6233\n",
      "\n",
      "    accuracy                           0.84     12466\n",
      "   macro avg       0.84      0.84      0.84     12466\n",
      "weighted avg       0.84      0.84      0.84     12466\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "FastText_cbow accuracy : 79.43205519011713 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81      6233\n",
      "           1       0.84      0.73      0.78      6233\n",
      "\n",
      "    accuracy                           0.79     12466\n",
      "   macro avg       0.80      0.79      0.79     12466\n",
      "weighted avg       0.80      0.79      0.79     12466\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Word2vec_sg accuracy : 83.25044120006417 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      6233\n",
      "           1       0.85      0.81      0.83      6233\n",
      "\n",
      "    accuracy                           0.83     12466\n",
      "   macro avg       0.83      0.83      0.83     12466\n",
      "weighted avg       0.83      0.83      0.83     12466\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Word2vec_cbow accuracy : 79.75292796406225 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81      6233\n",
      "           1       0.85      0.73      0.78      6233\n",
      "\n",
      "    accuracy                           0.80     12466\n",
      "   macro avg       0.80      0.80      0.80     12466\n",
      "weighted avg       0.80      0.80      0.80     12466\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(f\"FastText_sg accuracy : {accuracy_ft_sg} %\")\n",
    "print(report_ft_sg)\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"FastText_cbow accuracy : {accuracy_ft_cbow} %\")\n",
    "print(report_ft_cbow)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(f\"Word2vec_sg accuracy : {accuracy_w2v_sg} %\")\n",
    "print(report_w2v_sg)\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"Word2vec_cbow accuracy : {accuracy_w2v_cbow} %\")\n",
    "print(report_w2v_cbow)\n",
    "\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7aaf79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
